{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ce8947",
   "metadata": {},
   "source": [
    "## Class : C550-T301 Data Mining (2241-1)\n",
    "## Name : Rajib Samanta\n",
    "### Assignment : Week 3\n",
    "\n",
    "Download the labeled training dataset from this link: Bag of Words Meets Bags of Popcorn. \n",
    "    https://www.kaggle.com/competitions/word2vec-nlp-tutorial/data\n",
    "    \n",
    "#### Part 1: Using the TextBlob Sentiment Analyzer\n",
    "1. Import the movie review data as a data frame and ensure that the data is loaded properly.\n",
    "2. How many of each positive and negative reviews are there?\n",
    "3. Use TextBlob to classify each movie review as positive or negative. Assume that a polarity score greater than or equal to zero is a positive sentiment and less than 0 is a negative sentiment.\n",
    "4. Check the accuracy of this model. Is this model better than random guessing?\n",
    "5. For up to five points extra credit, use another prebuilt text sentiment analyzer, e.g., VADER, and repeat steps (3) and (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2da6c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "#pip install textblob\n",
    "from textblob import TextBlob\n",
    "# pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "# pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "924befdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7e70641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rajibsamanta/Documents/Rajib/College/Sem6_fall_2023/Week3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the labeled training dataset  file ('labeledTrainData.tsv') from local:\n",
    "directory = '/Users/rajibsamanta/Documents/Rajib/College/Sem6_fall_2023/Week3' \n",
    "# Set the working directory\n",
    "os.chdir(directory)\n",
    "print(os.getcwd())\n",
    "# 1. Import the movie review data as a data frame and ensure that the data is loaded properly.\n",
    "\n",
    "file_name = \"labeledTrainData.tsv\"\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(file_name, delimiter='\\t', quoting=3)\n",
    "\n",
    "# Display few records.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d504a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Positive Reviews: 12500\n",
      "Number of Negative Reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "# 2. How many of each positive and negative reviews are there?\n",
    "\n",
    "# Count the number of positive (label=1) and negative (label=0) reviews\n",
    "positive_reviews = df[df['sentiment'] == 1].shape[0]\n",
    "negative_reviews = df[df['sentiment'] == 0].shape[0]\n",
    "\n",
    "print(\"Number of Positive Reviews:\", positive_reviews)\n",
    "print(\"Number of Negative Reviews:\", negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0f74fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  sentiment                                             review  \\\n",
      "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...   \n",
      "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...   \n",
      "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...   \n",
      "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...   \n",
      "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...   \n",
      "\n",
      "   polarity predicted_sentiment  \n",
      "0  0.001277            Positive  \n",
      "1  0.256349            Positive  \n",
      "2 -0.053941            Negative  \n",
      "3  0.134753            Positive  \n",
      "4 -0.024290            Negative  \n"
     ]
    }
   ],
   "source": [
    "# 3. Use TextBlob to classify each movie review as positive or negative. \n",
    "#   Assume that a polarity score greater than or equal to zero is a positive sentiment and less than 0 is a negative sentiment.\n",
    "\n",
    "# Function to classify sentiment based on polarity score\n",
    "def classify_sentiment(polarity):\n",
    "    if polarity >= 0:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Apply sentiment analysis using TextBlob and classify sentiment\n",
    "df['polarity'] = df['review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "#df['sentiment'] = df['polarity'].apply(classify_sentiment)\n",
    "\n",
    "df['predicted_sentiment'] = df['polarity'].apply(classify_sentiment)\n",
    "\n",
    "# Print the first few rows of the DataFrame with sentiment labels\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c076b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id sentiment                                             review  \\\n",
      "0  \"5814_8\"  Positive  \"With all this stuff going down at the moment ...   \n",
      "1  \"2381_9\"  Positive  \"\\\"The Classic War of the Worlds\\\" by Timothy ...   \n",
      "2  \"7759_3\"  Negative  \"The film starts with a manager (Nicholas Bell...   \n",
      "3  \"3630_4\"  Negative  \"It must be assumed that those who praised thi...   \n",
      "4  \"9495_8\"  Positive  \"Superbly trashy and wondrously unpretentious ...   \n",
      "\n",
      "   polarity predicted_sentiment  \n",
      "0  0.001277            Positive  \n",
      "1  0.256349            Positive  \n",
      "2 -0.053941            Negative  \n",
      "3  0.134753            Positive  \n",
      "4 -0.024290            Negative  \n"
     ]
    }
   ],
   "source": [
    "# map the orginal dataset for positive and negative\n",
    "df['sentiment'] = df['sentiment'].map({1: 'Positive',0: 'Negative'})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80116a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_predictions: 1712600.00%\n",
      "total_predictions: 2500000.00%\n",
      "Accuracy: 68.50%\n"
     ]
    }
   ],
   "source": [
    "# 4. Check the accuracy of this model. Is this model better than random guessing?\n",
    "\n",
    "\n",
    "# Calculate accuracy by comparing predicted sentiment with actual sentiment\n",
    "correct_predictions = (df['sentiment'] == df['predicted_sentiment']).sum()\n",
    "print(f\"correct_predictions: {correct_predictions * 100:.2f}%\")\n",
    "total_predictions = len(df)\n",
    "print(f\"total_predictions: {total_predictions * 100:.2f}%\")\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca7e45",
   "metadata": {},
   "source": [
    "### The accuracy is 68.50% significantly better than random guessing (where random guessing would give us around 50% accuracy in a binary sentiment classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79ffadab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob Accuracy: 68.50%\n",
      "VADER Accuracy: 69.41%\n"
     ]
    }
   ],
   "source": [
    "# 5. For up to five points extra credit, use another prebuilt text sentiment analyzer, e.g., VADER, and repeat steps (3) and (4).\n",
    "# Function to classify sentiment based on TextBlob polarity\n",
    "# Load the dataset into a pandas DataFrame agaian\n",
    "df = pd.read_csv(file_name, delimiter='\\t', quoting=3)\n",
    "\n",
    "def classify_sentiment_textblob(polarity):\n",
    "    return \"Positive\" if polarity >= 0 else \"Negative\"\n",
    "\n",
    "# Apply TextBlob sentiment analysis\n",
    "df['textblob_polarity'] = df['review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['textblob_sentiment'] = df['textblob_polarity'].apply(classify_sentiment_textblob)\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to classify sentiment based on VADER sentiment scores\n",
    "def classify_sentiment_vader(review):\n",
    "    sentiment_scores = vader_analyzer.polarity_scores(review)\n",
    "    compound_score = sentiment_scores['compound']\n",
    "    return \"Positive\" if compound_score >= 0 else \"Negative\"\n",
    "\n",
    "# Apply VADER sentiment analysis\n",
    "df['vader_sentiment'] = df['review'].apply(classify_sentiment_vader)\n",
    "\n",
    "# map the orginal dataset for positive and negative\n",
    "df['sentiment'] = df['sentiment'].map({1: 'Positive',0: 'Negative'})\n",
    "\n",
    "# Calculate accuracy for TextBlob\n",
    "textblob_accuracy = (df['sentiment'] == df['textblob_sentiment']).sum() / len(df)\n",
    "\n",
    "# Calculate accuracy for VADER\n",
    "vader_accuracy = (df['sentiment'] == df['vader_sentiment']).sum() / len(df)\n",
    "\n",
    "print(f\"TextBlob Accuracy: {textblob_accuracy * 100:.2f}%\")\n",
    "print(f\"VADER Accuracy: {vader_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab038ea",
   "metadata": {},
   "source": [
    "#### The accuracy of both TextBlob and VADER in classifying sentiments are mostly same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51c367",
   "metadata": {},
   "source": [
    "### Part 2: Prepping Text for a Custom Model\n",
    "If you want to run your own model to classify text, it needs to be in proper form to do so. The following steps will outline a procedure to do this on the movie reviews text.\n",
    "1. Convert all text to lowercase letters.\n",
    "2. Remove punctuation and special characters from the text.\n",
    "3. Remove stop words.\n",
    "4. Apply NLTK’s PorterStemmer.\n",
    "5. Create a bag-of-words matrix from your stemmed text (output from (4)), where each row is a word-count vector for a single movie review (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook). Display the dimensions of your bag-of-words matrix. The number of rows in this matrix should be the same as the number of rows in your original data frame.\n",
    "6. Create a term frequency-inverse document frequency (tf-idf) matrix from your stemmed text, for your movie reviews (see section 6.9 in the Machine Learning with Python Cookbook). Display the dimensions of your tf-idf matrix. These dimensions should be the same as your bag-of-words matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9973e9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  \"with all this stuff going down at the moment ...\n",
      "1  \"\\\"the classic war of the worlds\\\" by timothy ...\n",
      "2  \"the film starts with a manager (nicholas bell...\n",
      "3  \"it must be assumed that those who praised thi...\n",
      "4  \"superbly trashy and wondrously unpretentious ...\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas DataFrame agaian\n",
    "df = pd.read_csv(file_name, delimiter='\\t', quoting=3)\n",
    "# 1. Convert all text to lowercase letters.\n",
    "# Convert the 'review' column to lowercase\n",
    "df['review'] = df['review'].str.lower()\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify the conversion\n",
    "print(df[['review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dec3a0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  sentiment                                             review\n",
      "0  \"5814_8\"          1  with all this stuff going down at the moment w...\n",
      "1  \"2381_9\"          1  the classic war of the worlds by timothy hines...\n",
      "2  \"7759_3\"          0  the film starts with a manager nicholas bell g...\n",
      "3  \"3630_4\"          0  it must be assumed that those who praised this...\n",
      "4  \"9495_8\"          1  superbly trashy and wondrously unpretentious 8...\n"
     ]
    }
   ],
   "source": [
    "# 2. Remove punctuation and special characters from the text.\n",
    "# Function to remove punctuation and special characters\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # Define a regular expression pattern to match non-alphanumeric characters\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    \n",
    "    # Use the re.sub() function to replace matched characters with an empty string\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "# Apply the remove_punctuation function to the 'review' column\n",
    "df['review'] = df['review'].apply(remove_punctuation)\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify the removal of punctuation\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62cc6468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rajibsamanta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  stuff going moment mj ive started listening mu...\n",
      "1  classic war worlds timothy hines entertaining ...\n",
      "2  film starts manager nicholas bell giving welco...\n",
      "3  must assumed praised film greatest filmed oper...\n",
      "4  superbly trashy wondrously unpretentious 80s e...\n"
     ]
    }
   ],
   "source": [
    "# 3. Remove stop words.\n",
    "\n",
    "# Download NLTK stop words\n",
    "nltk.download('stopwords')\n",
    "# Function to remove stop words\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Join the filtered words back into a single string\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "#print(stop_words)\n",
    "# Apply the remove_stopwords function to the 'review' column\n",
    "df['review'] = df['review'].apply(remove_stopwords)\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify the removal of stop words\n",
    "print(df[['review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2fdce14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rajibsamanta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  sentiment                                             review\n",
      "0  \"5814_8\"          1  stuff go moment mj ive start listen music watc...\n",
      "1  \"2381_9\"          1  classic war world timothi hine entertain film ...\n",
      "2  \"7759_3\"          0  film start manag nichola bell give welcom inve...\n",
      "3  \"3630_4\"          0  must assum prais film greatest film opera ever...\n",
      "4  \"9495_8\"          1  superbl trashi wondrous unpretenti 80 exploit ...\n"
     ]
    }
   ],
   "source": [
    "# 4. Apply NLTK’s PorterStemmer.\n",
    "\n",
    "# Download NLTK stop words and initialize the Porter Stemmer\n",
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "# Function to remove punctuation, remove stop words, and apply stemming\n",
    "def preprocess_and_stem(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Apply stemming using the Porter Stemmer\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    \n",
    "    # Join the stemmed words back into a single string\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "# Apply the preprocess_and_stem function to the 'review' column\n",
    "df['review'] = df['review'].apply(preprocess_and_stem)\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify the preprocessing and stemming\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0ed37d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Bag-of-Words (BoW) Matrix: (25000, 92226)\n"
     ]
    }
   ],
   "source": [
    "# 5. Create a bag-of-words matrix from your stemmed text (output from (4)), where each row is a word-count vector for a single movie review (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook). Display the dimensions of your bag-of-words matrix. \n",
    "#.    The number of rows in this matrix should be the same as the number of rows in your original data frame.\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the 'review' column to create the BoW matrix\n",
    "bow_matrix = vectorizer.fit_transform(df['review'])\n",
    "\n",
    "# Display the dimensions of the BoW matrix\n",
    "print(\"Dimensions of the Bag-of-Words (BoW) Matrix:\", bow_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "553ba637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the TF-IDF Matrix: (25000, 92226)\n"
     ]
    }
   ],
   "source": [
    "# 6. Create a term frequency-inverse document frequency (tf-idf) matrix from your stemmed text, for your movie reviews (see section 6.9 in the Machine Learning with Python Cookbook). \n",
    "#.   Display the dimensions of your tf-idf matrix. These dimensions should be the same as your bag-of-words matrix.\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the 'review' column to create the TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['review'])\n",
    "\n",
    "# Display the dimensions of the TF-IDF matrix\n",
    "print(\"Dimensions of the TF-IDF Matrix:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f95fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
